#!/usr/bin/env python
# -*- coding: UTF-8 -*-
import csv
import copy
import inspect
import math
import os
import os.path
import re
import stat
import string
import subprocess
import sys
import time
from optparse import OptionParser, OptionGroup

from tempfile import mkdtemp
os.environ['MPLCONFIGDIR'] = mkdtemp()
from matplotlib.backend_bases import FigureCanvasBase
from matplotlib.figure import Figure, SubplotParams
from matplotlib.ticker import FuncFormatter
from matplotlib.colors import LogNorm
import matplotlib
import matplotlib.cm
import numpy
import yaml
import fcntl
import struct

from distutils import spawn

try:
    import platform
    import ctypes

    libcver = platform.libc_ver()
    if libcver[0] == 'libc':
        libc = ctypes.CDLL("libc.so.%s" % libcver[1])
    elif libcver[0] == 'glibc' and libcver[1].startswith("2."):
        libc = ctypes.CDLL("libc.so.6")
    elif len(platform.mac_ver()[0]) > 0:
        libc = ctypes.CDLL("libc.dylib")
    else:
        libc = None
    if libc:
        sync = libc.sync
    else:
        sync = lambda: None
except:
    sync = lambda: None


# A empty exception class
# used to catch managed exception and errors
class FioException(Exception):
    pass


# An exception used to store a figure
class FigureContainer(Exception):
    figure = property(lambda self: self._figure, None, None, "figure")

    def __init__(self, figure):
        self._figure = figure

    def __str__(self):
        return repr(self._figure)


def check_dev(blockdevice):
    try:
        blockdev = os.stat("/dev/%s" % blockdevice.replace("/dev/", "").replace('!', '/'))
        return stat.S_ISBLK(blockdev.st_mode)
    except Exception as e:
        return False

units = {
    'T': 1099511627776,
    'G': 1073741824,
    'M': 1048576,
    'K': 1024,
    'k': 1024,
    '': 1,
}
size_re = re.compile('(\\d+)([TGMKk]?)');

def parse_size(input_size, out_suffix=""):
    matcher = size_re.match("%s" % input_size)
    if matcher is not None:
        value = float(matcher.group(1))
        suffix = matcher.group(2)
        return value * units[suffix] / units[out_suffix]


# Define the register command decorator
stepsfuncs = {}


def step(func, *args, **kwargs):
    stepsfuncs[func.__name__] = func
    return func


checkscriptfunc = []


def checkscript(func, *args, **kwargs):
    checkscriptfunc.append(func)
    return func


class FioStat(object):
    label = property(lambda self: self._label, None, None, "label")
    values = property(lambda self: self._values, None, None, "all fio values")
    version = property(lambda self: self._values[0], None, None, "data version")
    read_bw = property(lambda self: self._values[6], None, None, "read bandwith")
    write_bw = property(lambda self: self._values[47], None, None, "write bandwith")
    read_iops = property(lambda self: self._values[7], None, None, "read iop/s")
    write_iops = property(lambda self: self._values[48], None, None, "write iop/s")
    # join Âµs to 2ms, skip 75ms and 750ms
    latencies  = property(lambda self: [reduce(lambda x,y: x+y, self._values[99:110])] + self._values[110:117] + [reduce(lambda x,y: x+y, self._values[117:119])]+ self._values[119:121], None, None, "IO latencies")
    read_percentiles = property(lambda self : self._read_percentiles, None, None, "read latencies bucket")
    write_percentiles = property(lambda self : self._write_percentiles, None, None, "write latencies bucket")

    def __init__(self, label, values):
        if len(values) < 1:
            raise FioException("invalid fio stat line for run label '%s': %s" % (label, values))
        self._values = values
        self._label = label
        if self.version == 3 and len(values) < 120:
            raise FioException("invalid fio stat line for run label '%s': %s" % (label, values))
        self._read_percentiles = {}
        for (key, value) in map(lambda x: x.split("="), self._values[17:37]):
            self._read_percentiles[key] = int(value) / 1000.0
        self._write_percentiles = {}
        for (key, value) in map(lambda x: x.split("="), self._values[58:78]):
            self._write_percentiles[key] = int(value) / 1000.0


# A class used as a container for command
# To add a new command, just add a staticmethod to this class
class CcissSteps(object):
    @staticmethod
    def get_cciss_select(slot, array=None, ld=None):
        select = ["ctrl", "slot=%s" % slot]
        if ld is not None:
            select.extend(["ld", "%s" % ld])
        elif array is not None:
            select.extend(["array", "%s" % array])
        return select

    @staticmethod
    def get_cciss_info(hpacucli, slot, ld=None, array=None):
        sync()
        argv = [hpacucli]
        argv.extend(CcissSteps.get_cciss_select(slot=slot))
        argv.extend(["ld", "all", "show", "detail"])
        check_ld = subprocess.Popen(argv, stdin=None, stdout=subprocess.PIPE)
        output = check_ld.communicate()[0]
        if check_ld.wait() != 0:
            return {}
        values = {}
        current_array = ""
        ld_list = {}
        array_list = {}
        for l in re.split("\n", output):
            for v in re.split("  +", l):
                entry = re.split(":", v)
                if len(entry) == 2:
                    key = entry[0].strip()
                    value = entry[1].strip()
                    if (key == 'Logical Drive'):
                        values = {}
                        current_ld = int(value)
                        ld_list[current_ld] = values
                        array_list[current_array][current_ld] = values
                        values['Array'] = current_array
                    else:
                        values[key] = value
                else:
                    m = re.search('\w*array ([A-Z]+)', l)
                    if m is not None:
                        current_array = m.group(1)
                        array_list[current_array] = {}
        if ld is not None:
            return_ld = ld_list.get(ld, {})
            if len(return_ld) > 0:
                return {ld: return_ld}
            else:
                return {}
        elif array is not None:
            return array_list.get(array, {})
        else:
            return array_list

    @staticmethod
    def touch_ld(hpacucli, slot, array=None, ld=None):
        ld_list = CcissSteps.get_cciss_info(slot=slot, array=array, ld=ld, hpacucli=hpacucli)
        if ld != None:
            ld_info = ld_list[ld]
        elif array != None:
            # Touch the last ld
            keys = ld_list.keys()
            keys.sort()
            keys.reverse()
            ld_info = ld_list[keys[0]]
        else:
            ld_info = {}
        if 'Disk Name' in ld_info:
            with open(ld_info['Disk Name'], 'wb', 0) as out:
                out.write("0")

    @staticmethod
    @checkscript
    def check_cciss(script_yaml):
        # hpacucli is not mandatory, don't failed on it
        try:
            script_yaml['defaults']['hpacucli'] = check_executable(script_yaml['defaults'].get('hpacucli', 'hpacucli'))
        except FioException as e:
            # keep it, will be thrown when needed
            script_yaml['defaults']['hpacucli'] = e

    @staticmethod
    @step
    def modify_cciss(object, command, hpacucli, slot=None, ld=None):
        if isinstance(hpacucli, FioException):
            raise hpacucli
        sync()
        identity = []
        identity.extend(["ctrl", "slot=%s" % slot])
        if object == "ld":
            identity.extend(["ld", "%s" % ld])
        cciss_args = [check_executable(hpacucli)]
        cciss_args.extend(identity)
        cciss_args.append("modify")
        cciss_args.extend(command.split(" "))
        hpacuclip = subprocess.Popen(cciss_args, stdin=None)
        return hpacuclip.wait()

    @staticmethod
    @step
    def wait_cciss_ld(hpacucli, slot, array=None, ld=None):
        if isinstance(hpacucli, FioException):
            raise hpacucli
        sync()
        while True:
            ld_list = CcissSteps.get_cciss_info(slot=slot, array=array, ld=ld, hpacucli=hpacucli)
            if len(ld_list) == 0:
                raise FioException("no ld to wait for")

            wait_ld = False
            for ld_info in ld_list.values():
                if ld_info.get("Parity Initialization Status", "") == "Initialization Completed":
                    continue
                elif ld_info.get("Parity Initialization Status", "") == "Queued":
                    wait_ld = True
                if "Parity Initialization Progress" in ld_info:
                    print "%s: %s" % (ld_info['Disk Name'], ld_info["Parity Initialization Progress"])
                    wait_ld = True
                if wait_ld:
                    time.sleep(30)
                    break
            if not wait_ld:
                break


    @staticmethod
    @step
    def do_delete_cciss(hpacucli, slot, array=None, ld=None):
        if isinstance(hpacucli, FioException):
            raise hpacucli
        if array is not None or ld is not None:
            ld_list = CcissSteps.get_cciss_info(slot=slot, array=array, ld=ld, hpacucli=hpacucli)
            if len(ld_list) == 0:
                return
            for ld_info in ld_list.values():
                if 'Disk Name' in ld_info:
                    blockdevice = ld_info['Disk Name']
                    if check_dev(blockdevice):
                        for mount_info in ld_info['Mount Points'].split(','):
                            if mount_info.strip() != 'None':
                                mount_point = mount_info.strip().split(' ')[0]
                                CommonCommands.do_unmount(mount_point=mount_point)
                        CommonCommands.clean_drive(blockdevice)
            argv = [hpacucli]
            argv.extend(CcissSteps.get_cciss_select(slot=slot, array=array, ld=ld))
            argv.extend(["delete", "forced"])
            hpacuclip = subprocess.Popen(argv, stdin=None)
            status = hpacuclip.wait()
            if status != 0:
                raise FioException("hpacucli failed with status %s" % status)
            sync()
        else:
            raise FioException("No cciss volume to destroy")

    @staticmethod
    @step
    def do_delete_all_cciss(hpacucli, slot, array=None):
        if isinstance(hpacucli, FioException):
            raise hpacucli
        if array is not None:
            while True:
                ld_list = CcissSteps.get_cciss_info(slot=slot, array=array, hpacucli=hpacucli)
                if len(ld_list) == 0:
                    break
                else:
                    CcissSteps.do_delete_cciss(hpacucli, slot, array)

    @staticmethod
    @step
    def do_cciss_create_ld(hpacucli, slot, raid=None, stripsize=0, size=0, array=None, ld=None, type='ld', datald=None, drives='all'):
        if isinstance(hpacucli, FioException):
            raise hpacucli
        CcissSteps.do_delete_cciss(hpacucli, slot, array, ld)
        if isinstance(drives, list):
            drives = ",".join(drives)
        argv = [hpacucli, "ctrl", "slot=%s" % slot, "create", "type=%s" % type, "drives=%s" % drives]
        if type != 'arrayr0' and raid is not None:
            argv.append("raid=%s" % raid)
        if stripsize > 0:
            argv.append("ss=%s" % stripsize)
        if size > 0:
            argv.append("size=%s" % int(parse_size(size, 'M')))
        if type == 'ldcache' and datald is not None:
            argv.append("datald=%s" % datald)
        print " ".join(argv)
        hpacuclip = subprocess.Popen(argv, stdin=None)
        status = hpacuclip.wait()
        # needs to touch the created ld, to be sure build is started
        if status == 0 and type != 'ldcache':
            CcissSteps.touch_ld(hpacucli, slot, array, ld)
        return status


    @staticmethod
    @step
    def do_cciss_add_ld(slot, raid, array, hpacucli, stripsize=0, size=0):
        if isinstance(hpacucli, FioException):
            raise hpacucli
        argv = [hpacucli]
        argv.extend(CcissSteps.get_cciss_select(slot, array=array))
        argv.extend(["create", "type=ld", "raid=%s" % raid])
        if stripsize > 0:
            argv.append("ss=%s" % stripsize)
        if size > 0:
            argv.append("size=%s" % size)
        hpacuclip = subprocess.Popen(argv, stdin=None)
        status = hpacuclip.wait()
        # needs to touch the created ld, to be sure build is started
        if status == 0:
            CcissSteps.touch_ld(hpacucli, slot, array)
        return status

    @staticmethod
    @step
    def do_cciss_jbod(slot, hpacucli, drives):
        if isinstance(hpacucli, FioException):
            raise hpacucli
        for drive in drives:
            hpacuclip = subprocess.Popen([hpacucli, "ctrl", "slot=%s" % slot, "create", "type=ld", "raid=0", "drives=%s" % drive], stdin=None)
            status = hpacuclip.wait()
            sync()
            if status != 0:
                return status
        return 0


class ZFS(object):
    @staticmethod
    @checkscript
    def check_zfs_commands(script_yaml):
        script_yaml['defaults']['zfs'] = check_executable(script_yaml['defaults'].get('zfs', 'zfs'))
        script_yaml['defaults']['zpool'] = check_executable(script_yaml['defaults'].get('zpool', 'zpool'))

    @staticmethod
    def zpool_list(zpool):
        argv = [zpool, "list", "-H" ]
        zpoolp = subprocess.Popen(argv, stdin=None, stdout=subprocess.PIPE)
        output = zpoolp.communicate()[0]
        status = zpoolp.wait()
        if status != 0:
            return {}
        zpool_info = {}
        for l in re.split("\n", output):
            entry = re.split(r"\t", l)
            zpool_info[entry[0]] = entry
        return zpool_info

    @staticmethod
    @step
    def do_destroy_zpool(zpool, name):
        if isinstance(zpool, FioException):
            raise zpool
        sync()
        zpool_info = ZFS.zpool_list(zpool)
        if name in zpool_info:
            zpoolp = subprocess.Popen([zpool, "destroy", name])
            status = zpoolp.wait()
            if status != 0:
                raise FioException("can't detroy zpool %s" % name)

    @staticmethod
    @step
    def do_create_zpool(zpool, name, vdev, pool_properties={}, fs_properties={}, mount_point=None):
        if isinstance(zpool, FioException):
            raise zpool
        sync()
        argv = [zpool, "create", "-f", name ]
        if len(pool_properties) > 0:
            for (key, value) in pool_properties.items():
                argv.extend(["-o", "%s=%s" % (key, value)])
        if len(fs_properties) > 0:
            for (key, value) in fs_properties.items():
                argv.extend(["-O", "%s=%s" % (key, value)])
        if mount_point is not None:
            argv.extend(["-m", mount_point])
        argv.extend(vdev)
        print " ".join(argv)
        zpoolp = subprocess.Popen(argv, stdin=None)
        status = zpoolp.wait()
        if status != 0:
            return status


class CGroup(object):
    @staticmethod
    @step
    def cgroup_prepare():
        mount_point = "/cgroup/blkio"
        status = CommonCommands.do_mount("iops", mount_point, "cgroup", ["blkio"])
        if status == 0:
            if not os.path.exists("/cgroup/blkio/fiorun"):
                os.mkdir("/cgroup/blkio/fiorun")
                return 0
            if not os.path.exists("/cgroup/blkio/fiorun/tasks"):
                raise FioException("/cgroup/blkio/fiorun is not a cgroup path")
        else:
            return status

    @staticmethod
    def sub_run_fio(pipe_fds, mountpoint, tunables, **kwargs):
        (csv_r_fd, csv_w_fd) = pipe_fds
        os.close(csv_r_fd)
        pid = os.getpid()
        if not os.path.isfile("/cgroup/blkio/fiorun/tasks"):
            raise FioException("cgroup blkio don't exists")

        subgroup = "/cgroup/blkio/fiorun/%s" % pid
        os.mkdir(subgroup)

        with open("%s/tasks" % subgroup, "w") as f:
            f.write("%s" % pid)
        if check_dev(mountpoint):
            device = os.stat(mountpoint).st_rdev
        else:
            device = os.stat(mountpoint).st_dev
        major = os.major(device)
        minor = os.minor(device) & ~15
        for (key, value) in tunables.items():
            with open("%s/%s" % (subgroup, key), "w") as f:
                f.write("%d:%d %s" % (major, minor, value))

        with os.fdopen(csv_w_fd, 'w') as csv_w:
            cvsoutput = csv.writer(csv_w, delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
            for (label, values) in Fio.do_fio(**kwargs):
                cvsoutput.writerow([label] + values)
        exit(0)

    @staticmethod
    @step
    def do_cgroup_fio(mount_point, tunables, label, fio, fio_script, opts=[], count=1, variables={}):
        CommonCommands.prepare_fio(label, fio, fio_script, opts, variables)

        (csv_r_fd, csv_w_fd) = os.pipe()
        try:
           # Fork a child process so the parent can exit.
           pid = os.fork()
        except OSError, e:
           raise Exception, "%s [%d]" % (e.strerror, e.errno)
        if (pid == 0):
            try:
                CGroup.sub_run_fio((csv_r_fd, csv_w_fd), mount_point, tunables,
                                   label=label, fio_script=fio_script, fio=fio, opts=opts, count=count, variables=variables)
            except Exception as e:
                print e
                exit(1)
        else:
            os.close(csv_w_fd)
            with os.fdopen(csv_r_fd, 'r') as csv_r:
                cvsinput = csv.reader(csv_r, delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
                for row in cvsinput:
                    yield (row[0], row[1:])
            sync()
            (pid, status) = os.waitpid(pid, 0)
            status = (status & ~255) >> 8
            os.rmdir("/cgroup/blkio/fiorun/%s" % pid)
            if status != 0:
                raise FioException("forked fio failed: %d" % status)


class Lvm(object):
    @staticmethod
    @step
    def do_lvm_purge(volumegroup=None):
        if volumegroup is not None and os.path.isdir("/dev/%s" % volumegroup):
            status = subprocess.Popen(["/sbin/vgremove", "-f", volumegroup]).wait()
            if status != 0:
                return status
        return subprocess.Popen(["/sbin/dmsetup", "remove_all"]).wait()

    @staticmethod
    @step
    def do_pvcreate(blockdevice=None):
        CommonCommands.clean_drive(blockdevice)
        return subprocess.Popen(["/sbin/pvcreate", "-ff", "-y", blockdevice]).wait()

    @staticmethod
    @step
    def do_vgcreate(name, blockdevices):
        argv = ["/sbin/vgcreate", name]
        argv.extend(blockdevices)
        return subprocess.Popen(argv).wait()

    @staticmethod
    @step
    def do_vgextend(name, blockdevices):
        argv = ["/sbin/vgextend", name]
        argv.extend(blockdevices)
        return subprocess.Popen(argv).wait()

    @staticmethod
    @step
    def do_lvcreate(name, volumegroup, extents = None, size=None, blockdevices=None):
        sync()
        argv = ["/sbin/lvcreate", "-n", name, "-y"]
        if extents is not None:
            argv.extend(["-l", extents])
        if size is not None:
            argv.extend(["-L", size])
        argv.append(volumegroup)
        if blockdevices is not None:
            argv.extend(blockdevices)
        print " ".join(argv)
        return subprocess.Popen(argv).wait()

    @staticmethod
    @step
    def do_lvconvert(name, type, poolmetadata=None, cachepool=None):
        argv = ["/sbin/lvconvert", "--type", type, "-y"]
        if poolmetadata is not None:
            argv.extend(["--poolmetadata", poolmetadata])
        if cachepool is not None:
            argv.extend(["--cachepool", cachepool])
        argv.append(name)
        return subprocess.Popen(argv).wait()

    @staticmethod
    @step
    def do_dmcache(volumegroup, logicalvolume, poolmetadata, pooldata, blockdevice, size):
        Lvm.do_vgextend(volumegroup, [blockdevice])
        meta_size = min(int(size)*1024/1000, 56)
        Lvm.do_lvcreate(poolmetadata, volumegroup, size="%dM" % (meta_size))
        Lvm.do_lvcreate(pooldata, volumegroup, size="%dG" % int(size))
        Lvm.do_lvconvert("%s/%s" % (volumegroup, pooldata), type="cache-pool", poolmetadata="%s/%s" % (volumegroup, poolmetadata))
        Lvm.do_lvconvert("%s/%s" % (volumegroup, logicalvolume), type="cache", cachepool="%s/%s" % (volumegroup, pooldata))


class Fio(object):
    @staticmethod
    @checkscript
    def check_fio(script_yaml):
        script_yaml['defaults']['fio'] = check_executable(script_yaml['defaults'].get('fio', 'fio'))

    @staticmethod
    @checkscript
    def check_fio_scripts(script_yaml):
        fio_scripts = script_yaml['defaults'].get('fio_scripts', 'fio_scripts')
        if not os.path.isdir(fio_scripts):
            fio_scripts = FioException("fio_scripts is not a folder: %s" % fio_scripts)
        script_yaml['defaults']['fio_scripts'] = fio_scripts

    @staticmethod
    def run_fio(fio, fio_script, opts = [], variables = {}, prepare=False):
        (script_r, script_w) = os.pipe()
        fio_args = [fio, "/dev/fd/%d" % script_r, "--minimal"]
        if len(opts) > 0:
            fio_args.extend(opts)
        fio_process = subprocess.Popen(fio_args, stdout=subprocess.PIPE, preexec_fn=lambda: os.close(script_w))
        os.close(script_r)

        # Parse the fio script as a template
        with open(fio_script, "r") as fio_script_file:
            for line in fio_script_file:
                try:
                    os.write(script_w, string.Template(line).substitute(variables))
                except KeyError as e:
                    raise FioException("Unknown variable: %s" % e)
                if prepare and line.find("[global]") >= 0:
                    os.write(script_w, "create_only=1\n")
                    continue
        os.close(script_w)

        fio_stdout = fio_process.communicate()[0]
        status = fio_process.wait()
        if status != 0:
            raise FioException("fio run failed: %s\n%s" % (status, fio_stdout))
        return fio_stdout

    @staticmethod
    def prepare_fio(label, fio, fio_script, opts=[], variables={}):
        variables_clean = Fio.get_fio_variables(label, variables)
        Fio.run_fio(fio, fio_script, opts, variables_clean, prepare=True)

    @staticmethod
    def get_fio_variables(label, variables={}):
        # if a variable is a dict, use the label as a key to the real value
        variables_clean = {}
        for (key, value) in variables.items():
            if isinstance(value, type({})):
                variables_clean[key] = value[label]
            else:
                variables_clean[key] = value
        return variables_clean

    @staticmethod
    @step
    def do_fio(label, fio, fio_script, opts=[], count=1, variables={}):
        if isinstance(fio, FioException):
            raise fio

        variables_clean = Fio.get_fio_variables(label, variables)

        Fio.prepare_fio(label, fio, fio_script, opts, variables)

        flush_perms = True
        for i in range(count):
            sync()
            if flush_perms:
                try:
                    with open('/proc/sys/vm/drop_caches', 'w') as drop_caches:
                        drop_caches.write('3')
                except IOError:
                    flush_perms = False
                    print "insufficient permissions to flush caches, results might be not reproductible"

            fio_stdout = CommonCommands.run_fio(fio, fio_script, opts, variables_clean)

            # The fio run output is cleaned to be parsable by a csv.reader
            # don't parse error line, display them
            for found in re.compile(r'^(\d+;fio-.*)?(.*)$', re.MULTILINE).findall(fio_stdout):
                if len(found[0]) > 0:
                    fio_stdout = found[0]
                    break
                elif len(found[1]) > 0:
                    print found[1]
            fio_stdout = fio_stdout.replace("%", "")

            # a while because this regex will not manage two consecutive string
            quote_string = re.compile(r'(^|;)([^;"\n]*[A-Za-z=][^;"\n]*)(;|$)')
            while True:
                # wrapping all textual values with a ".."
                (fio_stdout, count) = quote_string.subn(r'\1"\2"\3', fio_stdout)
                if count == 0:
                    break
            try:
                cvs_line = csv.reader(re.split("\n", fio_stdout), delimiter=';', quoting=csv.QUOTE_NONNUMERIC).next()
                yield (label, cvs_line)
            except ValueError as e:
                raise FioException("can't parse fio run output: %s\n%s" % (e, fio_stdout))

    @staticmethod
    @step
    def run_fio_scripts(fio_scripts, fio, result_folder, run_folder, directio=False, runtime=None, size=None, tests=['readrand', 'read', 'write', 'randrw']):
        if isinstance(fio_scripts, FioException):
            raise fio_scripts
        argv = ["%s/fio.sh" % fio_scripts]
        if not os.path.isdir(result_folder):
            if not os.path.exists(result_folder):
                os.makedirs(result_folder)
            else:
                raise FioException("results folder %s is not a directory" % result_folder)
        argv.extend(["-o", result_folder])
        if directio:
            argv.extend(["-d", "1"])
        else:
            argv.extend(["-d", "0"])
        if runtime is not None:
            argv.extend(["-s", "%s" % runtime])
        if size is not None:
            argv.extend(["-m", "%s" % int(parse_size(size, 'M'))])
        argv.extend(["-b", fio])
        argv.extend(["-w", run_folder])
        argv.extend(["-t", " ".join(tests)])
        print " ".join(argv)
        status = subprocess.Popen(argv, stdin=subprocess.PIPE).wait()
        return status


# A class used as a container for command
# To add a new command, just add a staticmethod to this class
class CommonCommands(object):

    @staticmethod
    @step
    def clean_drive(blockdevice):
        CommonCommands.do_unmount(blockdevice=blockdevice)
        req = 0x80081272 # BLKGETSIZE64, result is bytes as unsigned 64-bit integer (uint64)
        with open(blockdevice, 'w') as dev:
            buf = fcntl.ioctl(dev.fileno(), req, ' ' * 8)
            size64 = struct.unpack('L', buf)[0]
            dev.write('\0' * 1024 * 1024 )
            dev.seek(size64 - 1024 * 1024)
            dev.write('\0' * 1024 * 1024)

    @staticmethod
    @step
    def do_unmount(mount_point=None, part=None, blockdevice=None):
        if blockdevice is not None:
            if not check_dev(blockdevice):
                return True
            CommonCommands.do_unmount(part="/dev/%s" % blockdevice.replace('/dev/', '').replace('!', '/'))
            # substitution needed because of cciss/cXdX with HP's Smart Arrays
            old_path = os.getcwdu()
            os.chdir('/sys/block/%s' % blockdevice.replace('/dev/', '').replace('/', '!'))
            for d in filter(lambda x: stat.S_ISDIR(os.stat(x).st_mode) and os.path.exists("%s/dev" % x),
                            os.listdir('.')):
                if CommonCommands.do_unmount(part="/dev/%s" % d.replace('!', '/')) != 0:
                    os.chdir(old_path)
                    return False
            os.chdir(old_path)
            return 0
        if part is not None:
            proc_mount = open('/proc/mounts', 'r')
            for l in proc_mount.readlines():
                mounted = l.split(" ")
                if mounted[0] == part:
                    mount_point = mounted[1]
                    break
        if not mount_point or not os.path.isdir(mount_point):
            return 0
        old_path = os.getcwdu()
        os.chdir(mount_point)
        benchdir = os.stat(".")
        updir = os.stat("..")
        os.chdir(old_path)
        if benchdir.st_dev != updir.st_dev:
            return subprocess.Popen(["umount", mount_point]).wait()

    @staticmethod
    @step
    def do_part(blockdevice, stripsize=0, stripcount=0, size=0):
        CommonCommands.do_unmount(blockdevice=blockdevice)
        sfdisk_args = ["sfdisk", "-L"]
        if stripsize != 0 and stripcount != 0:
            while stripsize * 2 > 63:
                stripsize /= 2
                stripcount *= 2
            sfdisk_args.extend(["-uC", "-H", "%s" % stripcount, "-S", "%s" % (stripsize * 2)])
            sizeratio = stripcount * stripsize * 2 / 1024
        else:
            sfdisk_args.extend(["-uM"])
            sizeratio = 1
        sfdisk_args.append(blockdevice)
        sfdisk = subprocess.Popen(sfdisk_args, stdin=subprocess.PIPE)
        if size == 0:
            input = "1,,,\n"
        else:
            input = "1,%d,,\n" % (size / sizeratio)

        sfdisk.communicate(input=input)
        if sfdisk.wait() == 0:
            sync()
            return subprocess.Popen(["blockdev", "--flushbufs", blockdevice]).wait()
        else:
            return False

    @staticmethod
    @step
    def do_fs_xfs(part, logdev=None, stripsize=0, stripcount=0):
        CommonCommands.do_unmount(part=part)
        if not check_dev(part):
            return False
        if logdev and not check_dev(logdev):
            return False
        mkfs_args = ["mkfs.xfs", "-f", "-L", "bench"]
        if logdev:
            mkfs_args.extend(["-l", "logdev=%s" % logdev, "-l", "size=2136997888"])
        if stripsize != 0 and stripcount != 0:
            stripsize = int(parse_size(stripsize, ''))
            mkfs_args.extend(["-d", "su=%d" % stripsize, "-d", "sw=%s" % stripcount])
        mkfs_args.append(part)
        print " ".join(mkfs_args)
        return subprocess.Popen(mkfs_args).wait()

    @staticmethod
    @step
    def do_mount(part, mount_point, fs_type, options=[]):
        CommonCommands.do_unmount(mount_point=mount_point)
        sync()
        if not os.path.isdir(mount_point):
            if not os.path.exists(mount_point):
                os.makedirs(mount_point)
            else:
                raise FioException("mount point %s is not a directory" % mount_point)
        mount_args = ["mount", "-t", fs_type]
        if len(options) > 0:
            mount_args.append("-o")
            mount_args.append(",".join(options))
        mount_args.append(part)
        mount_args.append(mount_point)
        return subprocess.Popen(mount_args).wait()

    @staticmethod
    @step
    def do_mount_xfs(part, mount_point, logdev=None, noatime=True, inode64=True):
        options = []
        if noatime:
            options.append("noatime")
        if inode64:
            options.append("inode64")
        if logdev:
            options.append("logdev=%s" % logdev)
        return CommonCommands.do_mount(part, mount_point, 'xfs', options)

    @staticmethod
    @step
    def sched_tune(blockdevice, scheduler=None, tunes={}):
        if scheduler:
            scheduler_file = '/sys/block/%s/queue/scheduler' % blockdevice.replace('/dev/', '').replace('/', '!')
            stat_info = os.stat(scheduler_file)
            if not stat.S_ISREG(stat_info.st_mode):
                raise FioException("invalid scheduler controler: %s", scheduler_file)
            with open(scheduler_file, "w") as f:
                f.write(scheduler)
        if len(tunes) > 0:
            scheduler_dir = '/sys/block/%s/queue/iosched' % blockdevice.replace('/dev/', '').replace('/', '!')
            stat_info = os.stat(scheduler_dir)
            if not stat.S_ISDIR(stat_info.st_mode):
                raise FioException("invalid scheduler directory controler: %s", scheduler_dir)
            for (tune, value) in tunes.items():
                tune_file = '%s/%s' % (scheduler_dir, tune )
                stat_info = os.stat(tune_file)
                if not stat.S_ISREG(stat_info.st_mode):
                    raise FioException("invalid scheduler tuner file: %s", tune_file)
                with open(tune_file, "w") as f:
                    f.write("%s" % value)

    @staticmethod
    @step
    def clean(dir):
        try:
            for root, subFolders, files in os.walk(dir, topdown=False):
                for folder in subFolders:
                    os.rmdir(os.path.join(root, folder))
                for onefile in files:
                    os.remove(os.path.join(root, onefile))
        except OSError as e:
            raise FioException("clean %s failed: %s" % (dir, e))

    @staticmethod
    @step
    def mkpath(dir):
        old_path = os.getcwdu()
        os.chdir(os.path.sep)
        for step in dir.split(os.path.sep)[1:]:
            try:
                if not stat.S_ISDIR(os.stat(step).st_mode):
                    raise FioException("a element of path is not a directory: %s%s%s" % (os.getcwdu(), os.path.sep, step))
            except OSError as e:
                if e.errno == 2 and e.filename == step:
                    try:
                        os.mkdir(step)
                    except OSError as e:
                        raise FioException("cant create directory %s%s%s: %s" % (os.getcwdu(), os.path.sep, step, e))
                else:
                    raise FioException("cant create directory %s%s%s: s" % (os.getcwdu(), os.path.sep, step, e))
            os.chdir(step)
        os.chdir(old_path)

    @staticmethod
    @checkscript
    def check_fio(script_yaml):
        script_yaml['defaults']['reboot'] = check_executable(script_yaml['defaults'].get('reboot', 'reboot'))

    @staticmethod
    @step
    def reboot(reboot, skipfile, step):
        if isinstance(reboot, FioException):
            raise reboot
        if os.path.isfile(skipfile):
            with open(skipfile, "w") as f:
                f.write("%d\n" % (step + 1))
        sync()
        status = subprocess.Popen([reboot]).wait()
        if status == 0:
            exit(0)
        else:
            return status


def run_script(script, debug):
    fio_values = []
    for (f, kwargs) in script:
        print "******* %s(%s)" % (f.__name__, kwargs)
        if debug:
            continue
        try:
            execute = f(**kwargs)
        except TypeError as e:
            raise FioException("%s failed: '%s', command parameters: %s" % (f.__name__, e, kwargs))
        if type(execute) == type(1) and execute != 0:
            raise FioException("%s failed: %s" % (f.__name__, execute))
        elif execute is False:
            raise FioException("%s failed: %s" % (f.__name__, execute))
        elif execute.__class__.__name__ == 'generator':
            for yielded in execute:
                if type(yielded) == type(()) and len(yielded) == 2:
                    fio_values.append(FioStat(yielded[0], yielded[1]))

    return fio_values


def run_yaml(script_yaml, start, end, debug):
    script = []
    step = 0
    if start is not None:
        step = start
    for cmd in script_yaml['run'][start:end]:
        # if the command is a plain string,
        # it's a command without arguments
        if type(cmd) == type(""):
            cmd = {cmd: None}
        cmd_name = cmd.keys()[0]
        cmd_args = cmd[cmd_name]
        if cmd_args == None:
            cmd_args = {}
        if cmd_name not in stepsfuncs:
            print "unknown %s" % cmd_name
        if cmd_name not in stepsfuncs:
            raise FioException("unknown action: %s" % cmd_name)
        cmd_func = stepsfuncs[cmd_name]
        kwargs = {}
        # Enumerate all argument in the function, and check from where
        # to find the value
        for arg_name in inspect.getargspec(cmd_func).args:
            if arg_name in cmd_args:
                kwargs[arg_name] = cmd_args[arg_name]
                del cmd_args[arg_name]
            elif arg_name == 'variables':
                kwargs[arg_name] = script_yaml['variables']
            elif arg_name in script_yaml['defaults']:
                kwargs[arg_name] = script_yaml['defaults'][arg_name]
            elif arg_name == 'step':
                kwargs[arg_name] = step
        # not all arguments from the yaml file used, something is wrong
        if len(cmd_args) > 0:
            raise FioException("Unused argument %s for %s" % (cmd_args.keys(), cmd_name))
        script.append((cmd_func, kwargs))
        step += 1
    return run_script(script, debug)


def plot(fio_values, mode="bw", filename=None, title=None):
    column_labels = ["<=2", "4", "10", "20", "50", "100", "250", "500", "1000", "2000", ">=2000"]
    latencies_steps = [2, 4, 10, 20, 50, 100, 250, 500, 1000, 2000, 5000]
    row_labels = []
    ms_values = []
    bw_values_read = []
    bw_values_write = []
    iops_values_read = []
    iops_values_write = []
    for row in fio_values:
        row_labels.append(row.label)
        bw_values_read.append(row.read_bw)
        iops_values_read.append(row.read_iops)
        bw_values_write.append(row.write_bw)
        iops_values_write.append(row.write_iops)
        ms_values.append(row.latencies)

    x = numpy.arange(len(ms_values))
    y = numpy.array(latencies_steps[:])
    X, Y = numpy.meshgrid(x, y)

    waitarray = numpy.array(ms_values).transpose()
    maxwait = numpy.amax(ms_values)
    normalized = waitarray / maxwait * 1000

    fig = Figure(subplotpars=SubplotParams(left=0.1, right=0.85, bottom=0.05))
    if title is not None:
        fig.suptitle(title)
    ax2 = fig.add_subplot(1, 1, 1)
    ax1 = ax2.twinx()

    ax2.set_xticks(numpy.arange(len(row_labels)), minor=False)
    ax2.set_xticklabels(row_labels, minor=False)
    ax2.set_xlim(-0.5, len(row_labels) - 0.5)

    #ax1.set_ylim(bottom=-1, top=11)
    ax1.set_yticks(latencies_steps)
    ax1.set_yticklabels(column_labels, minor=False)
    ax1.set_yscale('log')

    colors_range = [[2, 4, 10, 20, 50, 100, 250, 500, 1000, 2000, 5000]]
    colors = numpy.array(colors_range * len(row_labels)).transpose()
    latency_spots = ax1.scatter(X.ravel(), Y.ravel(), c=colors.ravel(), s=normalized, alpha=0.5, cmap="jet",
                                norm=LogNorm())
    #cbar = fig.colorbar(latency_spots, ax=[ax1, ax2], drawedges=False, orientation="horizontal")
    #cbar.set_label('latency color scale')
    previous = map(lambda x: x.read_percentiles["50.00"], fio_values)
    ax1.plot(previous, 'b-', )
    alpha = 1.0
    for bucket in ("90.00", "95.00", "99.00"):
        current = map(lambda x: x.read_percentiles[bucket], fio_values)
        alpha /= 2
        ax1.plot(current, 'b-', alpha=alpha)
        #ax1.fill_between(numpy.arange(len(ms_values)), previous, current, facecolor='blue', alpha=alpha)
        previous = current

    previous = map(lambda x: x.write_percentiles["50.00"], fio_values)
    ax1.plot(previous, 'g-', )
    alpha = 1.0
    for bucket in ("90.00", "95.00", "99.00"):
        current = map(lambda x: x.write_percentiles[bucket], fio_values)
        alpha /= 2
        ax1.plot(current, 'g-', alpha=alpha)
        #ax1.fill_between(numpy.arange(len(ms_values)), previous, current, facecolor='green', alpha=alpha)
        previous = current

    # Draw the bw or io/s line
    if mode == "bw":
        symbol = "k"
        magnitude_symbols = ["M", "G", "T"]
        to_plot_read = bw_values_read
        to_plot_write = bw_values_write
        ylabel = 'bandwidth'
        radix = 1024
        base = 8
        y_max = numpy.array(to_plot_read + to_plot_write).max()
        y_max_new = math.pow(2, math.ceil(math.log(y_max, 2)))
    else:
        symbol = ""
        magnitude_symbols = ["k", "M", "G", "T"]
        to_plot_read = iops_values_read
        to_plot_write = iops_values_write
        ylabel = 'io/s'
        radix = 1000
        base = 10
        y_max = (numpy.array(to_plot_read) + numpy.array(to_plot_write)).max()
        y_max_new = math.ceil(y_max / 5.0) * 5

    # pop start from the end
    magnitude_symbols.reverse()

    max_plot = max(numpy.amax(to_plot_read), numpy.amax(to_plot_write))
    if max_plot != 0:
        max_plot = math.pow(base, math.ceil(math.log(max_plot, base)))

    factor = 1
    max_plot_temp = max_plot
    while max_plot_temp > radix * 1.5:
        max_plot_temp /= radix
        factor *= radix
        symbol = magnitude_symbols.pop()

    if radix == 1024 and symbol:
        symbol += 'i'

    ax2.set_ylabel(ylabel, color='b')
    for tl in ax2.get_yticklabels():
        tl.set_color('b')
    formatter = FuncFormatter(lambda x, y: '%1.0f %s' % (x / factor, symbol))
    ax2.yaxis.set_major_formatter(formatter)
    if mode == "iops":
        ax2.plot(x, numpy.array(to_plot_read) + numpy.array(to_plot_write), 'k.-')
    else:
        ax2.plot(x, to_plot_read, 'b.-')
        ax2.plot(x, to_plot_write, 'g+-')

    ax2.set_ylim(0, y_max_new * 1.05)
    yticks = map(lambda x: (1.0 * x / base) * y_max_new, range(base + 1))
    ax2.set_yticks(yticks, minor=False)

    if filename:
        canvas = FigureCanvasBase(fig)
        canvas.print_figure(filename)
    else:
        # import only when needed, it uses X11
        import matplotlib.pyplot

        matplotlib.pyplot.show(fig)


def plot2(fio_values, mode="bw", filename=None, title=None):
    fig = Figure(subplotpars=SubplotParams(left=0.1, right=0.85, bottom=0.05))
    if title is not None:
        fig.suptitle(title)
    ax = fig.add_subplot(1, 1, 1)
    ax.set_xscale('log')
    plotted = []
    for row in fio_values:
        reversed = map(lambda (x, y) : [y, float(x)], row.read_percentiles.items())
        values = numpy.sort(reversed, axis=0).transpose()
        plotted.extend(ax.plot(values[0], values[1],"-.", label="%s read" % row.label))
    plotted.reverse()
    for row in fio_values:
        previous = plotted.pop()
        reversed = map(lambda (x,y) : [y, float(x)], row.write_percentiles.items())
        values = numpy.sort(reversed, axis=0).transpose()
        ax.plot(values[0], values[1],"-+", color=previous.get_color(), label="%s write" % row.label)
    ax.set_xlim(0.5, 5000)
    # plotted, map(lambda x: x.label, fio_values), ,
    ax.legend(loc='lower right')
    canvas = FigureCanvasBase(fig)
    canvas.print_figure(filename)


def save_csv(fio_values, filename):
    with open(filename, 'wb') as csvfile:
        cvsoutput = csv.writer(csvfile, delimiter=',',
                               quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
        for row in fio_values:
            cvsoutput.writerow([row.label] + row.values)


def read_csv(filename, values=[]):
    with open(filename, 'rb') as csvfile:
        csv_input = csv.reader(csvfile, delimiter=',', quotechar='"', quoting=csv.QUOTE_NONNUMERIC)
        for row in csv_input:
            if row:
                values.append(FioStat(row[0], row[1:]))
    return values


def exec_embeded_plot(code, **kwargs):
    try:
        exec code in globals(), kwargs
    except FigureContainer as e:
        canvas = FigureCanvasBase(e.figure)
        canvas.print_figure(kwargs['filename'])


def check_executable(filename):
    if filename is None:
        raise FioException("no command given")
    filename_path = spawn.find_executable(filename)
    if filename_path is not None:
        try:
            if not os.access(filename_path, os.X_OK):
                return FioException("no executable command '%s'" % filename_path)
        except OSError as e:
            return FioException("no valid command path '%s': '%s'" % (filename_path, e))
    else:
        return FioException("command '%s' not found in path" % filename)
    return filename_path


def read_yaml(filename, template, defaults, variables, skip, end, debug):
    try:
        yaml_file = open(filename)
        script_yaml = yaml.safe_load(yaml_file)
        yaml_file.close()
    except (yaml.parser.ParserError,yaml.scanner.ScannerError)  as e:
        print "invalid yaml file %s:" % filename
        print e
        return

    #####
    # Merge the template and the file
    if template is not None:
        #Run is over written
        if script_yaml.get('run') is None and template.get('run') is not None:
            # a copy is needed because script execution modify the object
            script_yaml['run'] = copy.deepcopy(template['run'])
        # other sections are merged
        for section in ('defaults', 'variables', 'plot', 'csv'):
            if section in template:
                if section not in script_yaml:
                    script_yaml[section] = {}
                for (key, value) in template[section].items():
                    if key not in script_yaml[section]:
                        script_yaml[section][key] = value

    if not 'defaults' in script_yaml:
        script_yaml['defaults'] = {}
    for (key, value) in defaults.items():
        script_yaml['defaults'][key] = value

    if not 'variables' in script_yaml:
        script_yaml['variables'] = {}
    for (key, value) in variables.items():
        script_yaml['variables'][key] = value

    parsed = string.Template(yaml.dump(script_yaml)).substitute(script_yaml['variables'])
    script_yaml = yaml.safe_load(parsed)

    # check the executable path
    for f in checkscriptfunc:
        f(script_yaml)

    fio_values = run_yaml(script_yaml, skip, end, debug)
    if len(fio_values) > 0:
        if 'csv' in script_yaml:
            save_csv(fio_values, **script_yaml['csv'])
        if 'code' not in script_yaml['plot']:
            plot(fio_values, **script_yaml['plot'])
        else:
            args = script_yaml['plot']
            args['fio_values'] = fio_values
            exec_embeded_plot(**args)


def main():
    parser = OptionParser(usage="\n%prog [options] yaml_script+\n%prog -c [options] csv_values+")

    yaml_group = OptionGroup(parser, "Yaml script execution")
    yaml_group.add_option("-V", "--variable", dest="variables", action="append", default=[])
    yaml_group.add_option("-D", "--default", dest="defaults", action="append", default=[])
    yaml_group.add_option("-v", "--verbose", action="store_true", dest="verbose", default=False)
    yaml_group.add_option("-s", "--skip", action="store", dest="skip", default=None, type=type(0))
    yaml_group.add_option("-S", "--skipfile", action="store", dest="skipfile", default=None)
    yaml_group.add_option("-1", "--onestep", action="store", dest="onestep", default=None, type=type(0))
    yaml_group.add_option("-t", "--template", action="store", dest="template", default=None)
    yaml_group.add_option("-d", "--debug", action="store_true", dest="debug", default=False)

    parser.add_option_group(yaml_group)

    csv_group = OptionGroup(parser, "Plot from a list of csv")
    csv_group.add_option("-c", "--csv", action="store_true", dest="csv_input", default=False)
    csv_group.add_option("-m", "--mode", action="store", dest="graph_mode", default=None, type="choice", choices=("bw", "iops"))
    csv_group.add_option("-p", "--png", action="store", dest="png_output", default=None, type=type(""))
    csv_group.add_option("-T", "--title", action="store", dest="graph_title", default=None, type=type(""))
    csv_group.add_option("-Y", "--yaml", action="store", dest="yaml", default=None, type=type(""))
    parser.add_option_group(csv_group)

    (options, args) = parser.parse_args()

    if options.template is not None:
        try:
            yaml_file = open(options.template)
            template = yaml.safe_load(yaml_file)
            yaml_file.close()
        except yaml.parser.ParserError as e:
            print "invalid yaml template %s:" % options.template
            print e
            return
    else:
        template = None

    variables = {}
    for default in options.variables:
        (key, value) = default.split("=")
        variables[key] = value

    defaults = {}
    for default in options.defaults:
        (key, value) = default.split("=")
        if key == 'count':
            value = int(value)
        defaults[key] = value

    # check the range of steps to run
    # default to None, means everything as [None:None] select the whole array
    start = None
    end = None
    if options.skipfile is not None:
        try:
            if os.path.isfile(options.skipfile):
                with open(options.skipfile, "r") as f:
                    skipline = f.read()
                    if len(skipline) != 0:
                        start = int(skipline)
            else:
                with open(options.skipfile, "w") as f:
                    f.write("%d\n" % 0)
            defaults['skipfile'] = options.skipfile
        except IOError as e:
            print e
            exit(1)
        except ValueError as e:
            print "cant parse skipe file %s content: '%s'" % (options.skipfile, skipline)
            exit(1)
    elif options.onestep is not None:
        start = options.onestep
        end = options.onestep + 1
    elif options.skip is not None:
        start = options.skip

    if len(args) == 0:
        parser.print_usage()
        exit(1)

    if not options.csv_input:
        for file_use in args:
            try:
                read_yaml(file_use, template, defaults, variables, start, end, options.debug)
            except FioException as e:
                print e
                break
    else:
        if options.yaml is not None:
            try:
                with open(options.yaml, "r") as yaml_file:
                    script_yaml = yaml.safe_load(yaml_file)
                graph_mode = script_yaml['plot']['mode']
                png_output = script_yaml['plot']['filename']
                graph_title = script_yaml['plot']['title']
            except yaml.parser.ParserError as e:
                print "invalid file %s:" % options.yaml
                print e
                exit(1)

        if options.graph_mode is not None:
            graph_mode = options.graph_mode
        if options.png_output is not None:
            png_output = options.png_output
        if options.graph_title is not None:
            graph_title = options.graph_title

        values = []
        for file_use in args:
            values = read_csv(file_use)

        exec_embeded_plot(script_yaml['plot']['code'], **{'fio_values': values, 'mode': graph_mode, 'filename': png_output, 'title': graph_title})


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit(1)
